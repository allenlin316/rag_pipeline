# RAG Pipeline

é€™æ˜¯ä¸€å€‹å®Œæ•´çš„ RAG (Retrieval-Augmented Generation) pipeline å¯¦ç¾ï¼ŒåŒ…å« retrieverã€reranker å’Œ generator ä¸‰å€‹ä¸»è¦çµ„ä»¶ã€‚

## åŠŸèƒ½ç‰¹è‰²

- ğŸ” **Retriever**: åŸºæ–¼å‘é‡ç›¸ä¼¼åº¦æª¢ç´¢ç›¸é—œæ–‡ä»¶
- ğŸ”„ **Reranker**: ä½¿ç”¨ reranker æ¨¡å‹é‡æ–°æ’åºæª¢ç´¢çµæœï¼ˆå¯é¸ï¼‰
- ğŸ¤– **Generator**: åŸºæ–¼æª¢ç´¢åˆ°çš„æ–‡ä»¶ç”Ÿæˆç¹é«”ä¸­æ–‡å›ç­”
- ğŸ“š **å‘é‡å„²å­˜**: ä½¿ç”¨ Chroma æŒä¹…åŒ–å‘é‡å„²å­˜
- âœ‚ï¸ **æ–‡æœ¬åˆ†å¡Š**: æ™ºèƒ½æ–‡æœ¬åˆ†å¡Šï¼Œæ”¯æ´é‡ç–Šå’Œèªç¾©å®Œæ•´æ€§
- ğŸ”Œ **API æ•´åˆ**: æ•´åˆç¾æœ‰çš„ embedding å’Œ reranker API
- âš™ï¸ **éˆæ´»é…ç½®**: å¯é¸æ“‡å•Ÿç”¨æˆ–ç¦ç”¨ reranker éšæ®µå’Œæ–‡æœ¬åˆ†å¡Š
- ğŸ‡¹ğŸ‡¼ **ä¸­æ–‡æ”¯æ´**: å…§å»º system prompt ç¢ºä¿ç¹é«”ä¸­æ–‡å›ç­”

## æ¶æ§‹åœ–

```
ç”¨æˆ¶æŸ¥è©¢ â†’ Retriever â†’ [Reranker] â†’ Generator â†’ å›ç­”
              â†“           â†“           â†“
          å‘é‡æœå°‹    é‡æ–°æ’åº    ç”Ÿæˆå›ç­”
                    (å¯é¸)
```

## å®‰è£

1. å…‹éš†å°ˆæ¡ˆï¼š
```bash
git clone <repository-url>
cd rag-pipeline
```

2. å®‰è£ä¾è³´ï¼š
```bash
pip install -r requirements.txt
```

3. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆå¿…éœ€ï¼‰ï¼š

**é‡è¦**: 
- API Key å¿…é ˆè¨­å®šåœ¨ `.env` æª”æ¡ˆä¸­ï¼Œä¸èƒ½é€šéå‘½ä»¤è¡Œåƒæ•¸å‚³é
- `.env` æª”æ¡ˆåŒ…å«æ•æ„Ÿè³‡è¨Šï¼Œè«‹ç¢ºä¿å°‡å…¶æ·»åŠ åˆ° `.gitignore` ä¸­

### å‘½ä»¤è¡Œåƒæ•¸

ä½ å¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ä¾†è‡ªå®šç¾©é…ç½®ï¼š

```bash
# ä½¿ç”¨é è¨­é…ç½®
python main.py

# è‡ªå®šç¾©æ¨¡å‹å’Œåƒæ•¸
python main.py \
    --embedding-model "Qwen3-Embedding-4B" \
    --generator-model "Qwen2.5-7B-Instruct" \
    --retriever-top-k 30 \
    --temperature 0.5 \
    --verbose

# ä½¿ç”¨è‡ªå®šç¾© API ç«¯é»
python main.py \
    --base-url "https://your-custom-endpoint.com/v1" \
    --collection-name "my_documents"

# ç¦ç”¨ Reranker éšæ®µï¼ˆè·³éé‡æ–°æ’åºï¼‰
python main.py --disable-reranker

# å•Ÿç”¨ Reranker éšæ®µï¼ˆé è¨­è¡Œç‚ºï¼‰
python main.py --enable-reranker

# ä½¿ç”¨ Ace1-24B-Security æ¨¡å‹ä¸¦å•Ÿç”¨ skip_special_tokens
python main.py --generator-model Ace1-24B-Security --skip-special-tokens

# ä½¿ç”¨å…¶ä»–æ¨¡å‹æ™‚ä¹Ÿå¯ä»¥è¨­å®š skip_special_tokens
python main.py --generator-model gemma-3-27b-it --skip-special-tokens

**æ³¨æ„**: `skip_special_tokens` åƒæ•¸æœƒæ”¾åœ¨ `extra_body` ä¸­å‚³éçµ¦ APIã€‚

**é‚è¼¯èªªæ˜**:
- **æ²’æœ‰çµ¦ `--skip-special-tokens` åƒæ•¸æ™‚**: `skip_special_tokens = true` (è·³éç‰¹æ®Š tokens)
- **æœ‰çµ¦ `--skip-special-tokens` åƒæ•¸æ™‚**: `skip_special_tokens = false` (ä¸è·³éç‰¹æ®Š tokens)

**API è«‹æ±‚æ ¼å¼**:
```json
{
    "model": "Ace1-24B-Security",
    "messages": [...],
    "extra_body": {
        "skip_special_tokens": true  // æˆ– falseï¼Œå–æ±ºæ–¼æ˜¯å¦çµ¦äº†åƒæ•¸
    }
}
```

### å€‹åˆ¥çµ„ä»¶ä½¿ç”¨

```python
from src.retriever import retriever
from src.reranker import reranker
from src.generator import generator

# 1. æª¢ç´¢ç›¸é—œæ–‡ä»¶
retrieved_docs = retriever(query, vector_store, top_k=10)

# 2. é‡æ–°æ’åº
reranked_docs = reranker(query, retrieved_docs, top_k=5)

# 3. ç”Ÿæˆå›ç­”
answer = generator(query, reranked_docs)
```

### è‡ªå®šç¾© API è¨­å®š

```python
from src.retriever import EmbeddingAPI
from src.reranker import RerankerAPI
from src.generator import GeneratorAPI

# è‡ªå®šç¾© API è¨­å®š
embedding_api = EmbeddingAPI(
    api_key="your_api_key",
    base_url="https://your-api-endpoint.com/v1"
)

reranker_api = RerankerAPI(
    api_key="your_api_key",
    base_url="https://your-api-endpoint.com/v1"
)

generator_api = GeneratorAPI(
    api_key="your_api_key",
    base_url="https://your-api-endpoint.com/v1"
)
```

### æ–‡æœ¬åˆ†å¡Šè¨­å®š

```python
from src.text_chunker import TextChunker, DocumentChunker

# å‰µå»ºè‡ªå®šç¾©æ–‡æœ¬åˆ†å¡Šå™¨
chunker = TextChunker(
    chunk_size=1000,      # æ¯å€‹å¡Šæœ€å¤§å­—ç¬¦æ•¸
    chunk_overlap=200,    # é‡ç–Šå­—ç¬¦æ•¸
    separator="\n\n",     # è‡ªç„¶åˆ†éš”ç¬¦
    min_chunk_size=100    # æœ€å°å¡Šå¤§å°
)

# å‰µå»ºæ–‡æª”åˆ†å¡Šå™¨
doc_chunker = DocumentChunker(chunker)

# æ‰‹å‹•åˆ†å¡Šæ–‡æª”
chunked_docs = doc_chunker.chunk_documents(documents)
```

## API ç«¯é»

### Embedding API
- **ç«¯é»**: `/embeddings`
- **æ¨¡å‹**: `Qwen3-Embedding-4B`
- **åŠŸèƒ½**: å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡è¡¨ç¤º

### Reranker API
- **ç«¯é»**: `/rerank`
- **æ¨¡å‹**: `bge-reranker-v2-m3`
- **åŠŸèƒ½**: é‡æ–°æ’åºæª¢ç´¢çµæœ

### Generator API
- **ç«¯é»**: `/chat/completions`
- **æ¨¡å‹**: `Qwen2.5-7B-Instruct`
- **åŠŸèƒ½**: ç”ŸæˆåŸºæ–¼æª¢ç´¢å…§å®¹çš„å›ç­”

## æª”æ¡ˆçµæ§‹

```
rag-pipeline/
â”œâ”€â”€ main.py                    # ä¸»è¦ RAG pipeline å¯¦ç¾
â”œâ”€â”€ config.py                  # é…ç½®ç®¡ç†ï¼ˆå‘½ä»¤è¡Œåƒæ•¸ï¼‰
â”œâ”€â”€ requirements.txt           # Python ä¾è³´
â”œâ”€â”€ README.md                 # èªªæ˜æ–‡ä»¶
â””â”€â”€ src/                      # æ ¸å¿ƒæ¨¡çµ„
    â”œâ”€â”€ __init__.py           # æ¨¡çµ„åˆå§‹åŒ–
    â”œâ”€â”€ retriever.py          # æª¢ç´¢æ¨¡çµ„
    â”œâ”€â”€ text_chunker.py       # æ–‡æœ¬åˆ†å¡Šæ¨¡çµ„
    â”œâ”€â”€ reranker.py           # é‡æ–°æ’åºæ¨¡çµ„
    â”œâ”€â”€ generator.py          # ç”Ÿæˆæ¨¡çµ„
    â””â”€â”€ rag_deepeval.py       # è©•ä¼°æ¨¡çµ„
```

## æ ¸å¿ƒé¡åˆ¥

### Document
æ–‡ä»¶è³‡æ–™çµæ§‹ï¼ŒåŒ…å«å…§å®¹ã€å…ƒæ•¸æ“šå’Œåˆ†æ•¸ã€‚

### VectorStore
ç°¡å–®çš„å‘é‡å„²å­˜å¯¦ç¾ï¼Œæ”¯æ´æ–‡ä»¶æ·»åŠ å’Œç›¸ä¼¼åº¦æœå°‹ã€‚

### TextChunker
æ™ºèƒ½æ–‡æœ¬åˆ†å¡Šå™¨ï¼Œæ”¯æ´ï¼š
- å¯é…ç½®çš„å¡Šå¤§å°å’Œé‡ç–Š
- è‡ªç„¶åˆ†éš”ç¬¦åˆ†å‰²
- å¥å­é‚Šç•Œåˆ†å‰²
- èªç¾©å®Œæ•´æ€§ä¿æŒ

### EmbeddingAPI
è™•ç†æ–‡æœ¬åˆ°å‘é‡çš„è½‰æ›ã€‚

### RerankerAPI
é‡æ–°æ’åºæª¢ç´¢çµæœä»¥æé«˜ç›¸é—œæ€§ã€‚

### GeneratorAPI
åŸºæ–¼æª¢ç´¢å…§å®¹ç”Ÿæˆç¹é«”ä¸­æ–‡å›ç­”ï¼ŒåŒ…å« system prompt ç¢ºä¿å›ç­”å“è³ªã€‚

### è©•ä¼°åŠŸèƒ½

å°ˆæ¡ˆåŒ…å«åŸºæ–¼ DeepEval çš„è©•ä¼°åŠŸèƒ½ï¼Œå¯ä»¥è©•ä¼° RAG Pipeline çš„è¡¨ç¾ï¼š

```python
from src.rag_deepeval import evaluate_rag_pipeline

# è©•ä¼° RAG Pipeline
evaluation_results = evaluate_rag_pipeline(
    query="ç”¨æˆ¶æŸ¥è©¢",
    actual_output="å¯¦éš›ç”Ÿæˆçš„å›ç­”",
    expected_output="æœŸæœ›çš„å›ç­”",
    retrieval_context=["æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡"],
    metrics=["faithfulness", "answer_relevancy"]
)

# æŸ¥çœ‹è©•ä¼°çµæœ
for metric_name, result in evaluation_results.items():
    print(f"{metric_name}: {result['score']}")
    print(f"åŸå› : {result['reason']}")
```

æ”¯æ´çš„è©•ä¼°æŒ‡æ¨™ï¼š
- **Faithfulness**: è©•ä¼°å›ç­”æ˜¯å¦å¿ å¯¦æ–¼æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
- **Answer Relevancy**: è©•ä¼°å›ç­”èˆ‡æŸ¥è©¢çš„ç›¸é—œæ€§
- **Contextual Precision**: è©•ä¼°æª¢ç´¢ä¸Šä¸‹æ–‡çš„ç²¾ç¢ºåº¦
- **Contextual Recall**: è©•ä¼°æª¢ç´¢ä¸Šä¸‹æ–‡çš„å¬å›ç‡
- **Contextual Relevancy**: è©•ä¼°æª¢ç´¢ä¸Šä¸‹æ–‡çš„ç›¸é—œæ€§

### è©•ä¼°æ¨¡å‹é…ç½®

è©•ä¼°åŠŸèƒ½ä½¿ç”¨è‡ªå®šç¾©çš„ LLM Judge æ¨¡å‹ä¾†é€²è¡Œè©•ä¼°åˆ¤æ–·ã€‚ä½ å¯ä»¥é€šéä»¥ä¸‹æ–¹å¼é…ç½®ï¼š

```bash
# ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸æŒ‡å®šè©•ä¼°æ¨¡å‹
python main.py --llm-judge-model "gpt-oss-120b"

# æˆ–åœ¨é…ç½®ä¸­è¨­å®š
python main.py --llm-judge-model "gemma-3-12b-it"
```

é è¨­çš„è©•ä¼°æ¨¡å‹æ˜¯ `gpt-oss-120b`ï¼Œä½ å¯ä»¥æ ¹æ“šéœ€è¦é¸æ“‡ä¸åŒçš„æ¨¡å‹ä¾†é€²è¡Œè©•ä¼°ã€‚

### å¿«é€Ÿæ¸¬è©¦åŠŸèƒ½

ç‚ºäº†æ–¹ä¾¿å¿«é€Ÿæ¸¬è©¦ RAG Pipelineï¼Œæˆ‘å€‘æä¾›äº†å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼Œåªè™•ç†è³‡æ–™é›†çš„ç¬¬ä¸€è¡Œï¼š

```bash
# å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼ˆåªè™•ç†ç¬¬ä¸€è¡Œè³‡æ–™ï¼‰
python main.py --dataset-name "your_dataset" --quick-test

# å®Œæ•´æ¸¬è©¦æ¨¡å¼ï¼ˆè™•ç†æ‰€æœ‰è³‡æ–™ï¼‰
python main.py --dataset-name "your_dataset"
```

å¿«é€Ÿæ¸¬è©¦æ¨¡å¼çš„ç‰¹é»ï¼š
- âš¡ **å¿«é€ŸåŸ·è¡Œ**ï¼šåªè™•ç†è³‡æ–™é›†çš„ç¬¬ä¸€è¡Œï¼Œç¯€çœæ™‚é–“
- ğŸ” **è©³ç´°è¼¸å‡º**ï¼šé¡¯ç¤º contextã€queryã€expected answer å’Œ generated answer
- ğŸ§ª **æ¸¬è©¦å‹å¥½**ï¼šé©åˆå¿«é€Ÿé©—è­‰ pipeline åŠŸèƒ½
- ğŸ“Š **å®Œæ•´æµç¨‹**ï¼šåŒ…å« retrieverã€reranker å’Œ generator æ‰€æœ‰éšæ®µ

## é…ç½®é¸é …

### æ¨¡å‹é¸æ“‡
- **Embedding æ¨¡å‹**: `Qwen3-Embedding-4B`
- **Reranker æ¨¡å‹**: `bge-reranker-v2-m3`
- **Generator æ¨¡å‹**: `Qwen2.5-7B-Instruct`

### åƒæ•¸èª¿æ•´
- **æª¢ç´¢æ•¸é‡**: `top_k` åƒæ•¸æ§åˆ¶æª¢ç´¢å’Œé‡æ–°æ’åºçš„æ–‡ä»¶æ•¸é‡
- **ç”Ÿæˆåƒæ•¸**: `max_tokens` å’Œ `temperature` æ§åˆ¶ç”Ÿæˆå“è³ª