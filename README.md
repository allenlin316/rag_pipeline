# RAG Pipeline

é€™æ˜¯ä¸€å€‹å®Œæ•´çš„ RAG (Retrieval-Augmented Generation) pipeline å¯¦ç¾ï¼ŒåŒ…å« retrieverã€reranker å’Œ generator ä¸‰å€‹ä¸»è¦çµ„ä»¶ã€‚

## åŠŸèƒ½ç‰¹è‰²

- ğŸ” **Retriever**: åŸºæ–¼å‘é‡ç›¸ä¼¼åº¦æª¢ç´¢ç›¸é—œæ–‡ä»¶
- ğŸ”„ **Reranker**: ä½¿ç”¨ reranker æ¨¡å‹é‡æ–°æ’åºæª¢ç´¢çµæœï¼ˆå¯é¸ï¼‰
- ğŸ¤– **Generator**: åŸºæ–¼æª¢ç´¢åˆ°çš„æ–‡ä»¶ç”Ÿæˆç¹é«”ä¸­æ–‡å›ç­”
- ğŸ“š **å‘é‡å„²å­˜**: ä½¿ç”¨ Chroma æŒä¹…åŒ–å‘é‡å„²å­˜
- âœ‚ï¸ **æ–‡æœ¬åˆ†å¡Š**: æ™ºèƒ½æ–‡æœ¬åˆ†å¡Šï¼Œæ”¯æ´é‡ç–Šå’Œèªç¾©å®Œæ•´æ€§
- ğŸ”Œ **API æ•´åˆ**: æ•´åˆç¾æœ‰çš„ embedding å’Œ reranker API
- âš™ï¸ **éˆæ´»é…ç½®**: å¯é¸æ“‡å•Ÿç”¨æˆ–ç¦ç”¨ reranker éšæ®µå’Œæ–‡æœ¬åˆ†å¡Š
- ğŸ‡¹ğŸ‡¼ **ä¸­æ–‡æ”¯æ´**: å…§å»º system prompt ç¢ºä¿ç¹é«”ä¸­æ–‡å›ç­”

## æ¶æ§‹åœ–

```
ç”¨æˆ¶æŸ¥è©¢ â†’ Retriever â†’ [Reranker] â†’ Generator â†’ å›ç­”
              â†“           â†“           â†“
          å‘é‡æœå°‹    é‡æ–°æ’åº    ç”Ÿæˆå›ç­”
                    (å¯é¸)
```

## å®‰è£

1. å…‹éš†å°ˆæ¡ˆï¼š
```bash
git clone <repository-url>
cd rag-pipeline
```

2. å®‰è£ä¾è³´ï¼š
```bash
pip install -r requirements.txt
```

3. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆå¿…éœ€ï¼‰ï¼š
```bash
# æ–¹æ³•ä¸€ï¼šä½¿ç”¨è¨­å®šè…³æœ¬ï¼ˆæ¨è–¦ï¼‰
python setup_env.py

# æ–¹æ³•äºŒï¼šæ‰‹å‹•å‰µå»º .env æª”æ¡ˆ
echo "API_KEY=your_api_key_here" > .env
```

**é‡è¦**: 
- API Key å¿…é ˆè¨­å®šåœ¨ `.env` æª”æ¡ˆä¸­ï¼Œä¸èƒ½é€šéå‘½ä»¤è¡Œåƒæ•¸å‚³é
- `.env` æª”æ¡ˆåŒ…å«æ•æ„Ÿè³‡è¨Šï¼Œè«‹ç¢ºä¿å°‡å…¶æ·»åŠ åˆ° `.gitignore` ä¸­

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨

```python
from src.retriever import Document, ChromaVectorStore
from src.generator import generator
from main import rag_pipeline
from config import init_config

# åˆå§‹åŒ–é…ç½®
config = init_config()

# å‰µå»ºå‘é‡å„²å­˜ï¼ˆå•Ÿç”¨æ–‡æœ¬åˆ†å¡Šï¼‰
vector_store = ChromaVectorStore(
    collection_name=config.collection_name,
    persist_directory=config.persist_directory,
    enable_chunking=True,  # å•Ÿç”¨æ–‡æœ¬åˆ†å¡Š
    chunk_size=1000,       # æ¯å€‹å¡Šæœ€å¤§1000å­—ç¬¦
    chunk_overlap=200      # é‡ç–Š200å­—ç¬¦
)

# æ·»åŠ æ–‡ä»¶åˆ°çŸ¥è­˜åº«
documents = [
    Document("æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹åˆ†æ”¯ã€‚"),
    Document("æ·±åº¦å­¸ç¿’ä½¿ç”¨ç¥ç¶“ç¶²çµ¡é€²è¡Œæ¨¡å¼è­˜åˆ¥ã€‚"),
    Document("è‡ªç„¶èªè¨€è™•ç†å°ˆæ³¨æ–¼è¨ˆç®—æ©Ÿç†è§£äººé¡èªè¨€ã€‚")
]

vector_store.add_documents(documents)

# åŸ·è¡Œ RAG pipeline
query = "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ"
answer = rag_pipeline(query, vector_store)
print(answer)
```

### å‘½ä»¤è¡Œåƒæ•¸

ä½ å¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ä¾†è‡ªå®šç¾©é…ç½®ï¼š

```bash
# ä½¿ç”¨é è¨­é…ç½®
python main.py

# è‡ªå®šç¾©æ¨¡å‹å’Œåƒæ•¸
python main.py \
    --embedding-model "Qwen3-Embedding-4B" \
    --generator-model "Qwen2.5-7B-Instruct" \
    --retriever-top-k 30 \
    --temperature 0.5 \
    --verbose

# ä½¿ç”¨è‡ªå®šç¾© API ç«¯é»
python main.py \
    --base-url "https://your-custom-endpoint.com/v1" \
    --collection-name "my_documents"

# ç¦ç”¨ Reranker éšæ®µï¼ˆè·³éé‡æ–°æ’åºï¼‰
python main.py --disable-reranker

# å•Ÿç”¨ Reranker éšæ®µï¼ˆé è¨­è¡Œç‚ºï¼‰
python main.py --enable-reranker

### å€‹åˆ¥çµ„ä»¶ä½¿ç”¨

```python
from src.retriever import retriever
from src.reranker import reranker
from src.generator import generator

# 1. æª¢ç´¢ç›¸é—œæ–‡ä»¶
retrieved_docs = retriever(query, vector_store, top_k=10)

# 2. é‡æ–°æ’åº
reranked_docs = reranker(query, retrieved_docs, top_k=5)

# 3. ç”Ÿæˆå›ç­”
answer = generator(query, reranked_docs)
```

### è‡ªå®šç¾© API è¨­å®š

```python
from src.retriever import EmbeddingAPI
from src.reranker import RerankerAPI
from src.generator import GeneratorAPI

# è‡ªå®šç¾© API è¨­å®š
embedding_api = EmbeddingAPI(
    api_key="your_api_key",
    base_url="https://your-api-endpoint.com/v1"
)

reranker_api = RerankerAPI(
    api_key="your_api_key",
    base_url="https://your-api-endpoint.com/v1"
)

generator_api = GeneratorAPI(
    api_key="your_api_key",
    base_url="https://your-api-endpoint.com/v1"
)
```

### æ–‡æœ¬åˆ†å¡Šè¨­å®š

```python
from src.text_chunker import TextChunker, DocumentChunker

# å‰µå»ºè‡ªå®šç¾©æ–‡æœ¬åˆ†å¡Šå™¨
chunker = TextChunker(
    chunk_size=1000,      # æ¯å€‹å¡Šæœ€å¤§å­—ç¬¦æ•¸
    chunk_overlap=200,    # é‡ç–Šå­—ç¬¦æ•¸
    separator="\n\n",     # è‡ªç„¶åˆ†éš”ç¬¦
    min_chunk_size=100    # æœ€å°å¡Šå¤§å°
)

# å‰µå»ºæ–‡æª”åˆ†å¡Šå™¨
doc_chunker = DocumentChunker(chunker)

# æ‰‹å‹•åˆ†å¡Šæ–‡æª”
chunked_docs = doc_chunker.chunk_documents(documents)
```

## API ç«¯é»

### Embedding API
- **ç«¯é»**: `/embeddings`
- **æ¨¡å‹**: `Qwen3-Embedding-4B`
- **åŠŸèƒ½**: å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡è¡¨ç¤º

### Reranker API
- **ç«¯é»**: `/rerank`
- **æ¨¡å‹**: `bge-reranker-v2-m3`
- **åŠŸèƒ½**: é‡æ–°æ’åºæª¢ç´¢çµæœ

### Generator API
- **ç«¯é»**: `/chat/completions`
- **æ¨¡å‹**: `Qwen2.5-7B-Instruct`
- **åŠŸèƒ½**: ç”ŸæˆåŸºæ–¼æª¢ç´¢å…§å®¹çš„å›ç­”

## æª”æ¡ˆçµæ§‹

```
rag-pipeline/
â”œâ”€â”€ main.py                    # ä¸»è¦ RAG pipeline å¯¦ç¾
â”œâ”€â”€ config.py                  # é…ç½®ç®¡ç†ï¼ˆå‘½ä»¤è¡Œåƒæ•¸ï¼‰
â”œâ”€â”€ setup_env.py               # ç’°å¢ƒè®Šæ•¸è¨­å®šè…³æœ¬
â”œâ”€â”€ example_usage.py           # ä½¿ç”¨ç¯„ä¾‹
â”œâ”€â”€ test_api.py                # API æ¸¬è©¦æª”æ¡ˆ
â”œâ”€â”€ test_config.py             # é…ç½®ç³»çµ±æ¸¬è©¦
â”œâ”€â”€ test_evaluation.py         # è©•ä¼°åŠŸèƒ½æ¸¬è©¦
â”œâ”€â”€ test_chunking.py           # æ–‡æœ¬åˆ†å¡Šæ¸¬è©¦
â”œâ”€â”€ test_generation_deepeval.py # DeepEval æ¸¬è©¦
â”œâ”€â”€ requirements.txt           # Python ä¾è³´
â”œâ”€â”€ README.md                 # èªªæ˜æ–‡ä»¶
â””â”€â”€ src/                      # æ ¸å¿ƒæ¨¡çµ„
    â”œâ”€â”€ __init__.py           # æ¨¡çµ„åˆå§‹åŒ–
    â”œâ”€â”€ retriever.py          # æª¢ç´¢æ¨¡çµ„
    â”œâ”€â”€ text_chunker.py       # æ–‡æœ¬åˆ†å¡Šæ¨¡çµ„
    â”œâ”€â”€ reranker.py           # é‡æ–°æ’åºæ¨¡çµ„
    â”œâ”€â”€ generator.py          # ç”Ÿæˆæ¨¡çµ„
    â””â”€â”€ rag_deepeval.py       # è©•ä¼°æ¨¡çµ„
```

## æ ¸å¿ƒé¡åˆ¥

### Document
æ–‡ä»¶è³‡æ–™çµæ§‹ï¼ŒåŒ…å«å…§å®¹ã€å…ƒæ•¸æ“šå’Œåˆ†æ•¸ã€‚

### VectorStore
ç°¡å–®çš„å‘é‡å„²å­˜å¯¦ç¾ï¼Œæ”¯æ´æ–‡ä»¶æ·»åŠ å’Œç›¸ä¼¼åº¦æœå°‹ã€‚

### TextChunker
æ™ºèƒ½æ–‡æœ¬åˆ†å¡Šå™¨ï¼Œæ”¯æ´ï¼š
- å¯é…ç½®çš„å¡Šå¤§å°å’Œé‡ç–Š
- è‡ªç„¶åˆ†éš”ç¬¦åˆ†å‰²
- å¥å­é‚Šç•Œåˆ†å‰²
- èªç¾©å®Œæ•´æ€§ä¿æŒ

### EmbeddingAPI
è™•ç†æ–‡æœ¬åˆ°å‘é‡çš„è½‰æ›ã€‚

### RerankerAPI
é‡æ–°æ’åºæª¢ç´¢çµæœä»¥æé«˜ç›¸é—œæ€§ã€‚

### GeneratorAPI
åŸºæ–¼æª¢ç´¢å…§å®¹ç”Ÿæˆç¹é«”ä¸­æ–‡å›ç­”ï¼ŒåŒ…å« system prompt ç¢ºä¿å›ç­”å“è³ªã€‚

### è©•ä¼°åŠŸèƒ½

å°ˆæ¡ˆåŒ…å«åŸºæ–¼ DeepEval çš„è©•ä¼°åŠŸèƒ½ï¼Œå¯ä»¥è©•ä¼° RAG Pipeline çš„è¡¨ç¾ï¼š

```python
from src.rag_deepeval import evaluate_rag_pipeline

# è©•ä¼° RAG Pipeline
evaluation_results = evaluate_rag_pipeline(
    query="ç”¨æˆ¶æŸ¥è©¢",
    actual_output="å¯¦éš›ç”Ÿæˆçš„å›ç­”",
    expected_output="æœŸæœ›çš„å›ç­”",
    retrieval_context=["æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡"],
    metrics=["faithfulness", "answer_relevancy"]
)

# æŸ¥çœ‹è©•ä¼°çµæœ
for metric_name, result in evaluation_results.items():
    print(f"{metric_name}: {result['score']}")
    print(f"åŸå› : {result['reason']}")
```

æ”¯æ´çš„è©•ä¼°æŒ‡æ¨™ï¼š
- **Faithfulness**: è©•ä¼°å›ç­”æ˜¯å¦å¿ å¯¦æ–¼æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
- **Answer Relevancy**: è©•ä¼°å›ç­”èˆ‡æŸ¥è©¢çš„ç›¸é—œæ€§
- **Contextual Precision**: è©•ä¼°æª¢ç´¢ä¸Šä¸‹æ–‡çš„ç²¾ç¢ºåº¦
- **Contextual Recall**: è©•ä¼°æª¢ç´¢ä¸Šä¸‹æ–‡çš„å¬å›ç‡
- **Contextual Relevancy**: è©•ä¼°æª¢ç´¢ä¸Šä¸‹æ–‡çš„ç›¸é—œæ€§

### è©•ä¼°æ¨¡å‹é…ç½®

è©•ä¼°åŠŸèƒ½ä½¿ç”¨è‡ªå®šç¾©çš„ LLM Judge æ¨¡å‹ä¾†é€²è¡Œè©•ä¼°åˆ¤æ–·ã€‚ä½ å¯ä»¥é€šéä»¥ä¸‹æ–¹å¼é…ç½®ï¼š

```bash
# ä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸æŒ‡å®šè©•ä¼°æ¨¡å‹
python main.py --llm-judge-model "gpt-oss-120b"

# æˆ–åœ¨é…ç½®ä¸­è¨­å®š
python main.py --llm-judge-model "gemma-3-12b-it"
```

é è¨­çš„è©•ä¼°æ¨¡å‹æ˜¯ `gpt-oss-120b`ï¼Œä½ å¯ä»¥æ ¹æ“šéœ€è¦é¸æ“‡ä¸åŒçš„æ¨¡å‹ä¾†é€²è¡Œè©•ä¼°ã€‚

### å¿«é€Ÿæ¸¬è©¦åŠŸèƒ½

ç‚ºäº†æ–¹ä¾¿å¿«é€Ÿæ¸¬è©¦ RAG Pipelineï¼Œæˆ‘å€‘æä¾›äº†å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼Œåªè™•ç†è³‡æ–™é›†çš„ç¬¬ä¸€è¡Œï¼š

```bash
# å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼ˆåªè™•ç†ç¬¬ä¸€è¡Œè³‡æ–™ï¼‰
python main.py --dataset-name "your_dataset" --quick-test

# å®Œæ•´æ¸¬è©¦æ¨¡å¼ï¼ˆè™•ç†æ‰€æœ‰è³‡æ–™ï¼‰
python main.py --dataset-name "your_dataset"
```

å¿«é€Ÿæ¸¬è©¦æ¨¡å¼çš„ç‰¹é»ï¼š
- âš¡ **å¿«é€ŸåŸ·è¡Œ**ï¼šåªè™•ç†è³‡æ–™é›†çš„ç¬¬ä¸€è¡Œï¼Œç¯€çœæ™‚é–“
- ğŸ” **è©³ç´°è¼¸å‡º**ï¼šé¡¯ç¤º contextã€queryã€expected answer å’Œ generated answer
- ğŸ§ª **æ¸¬è©¦å‹å¥½**ï¼šé©åˆå¿«é€Ÿé©—è­‰ pipeline åŠŸèƒ½
- ğŸ“Š **å®Œæ•´æµç¨‹**ï¼šåŒ…å« retrieverã€reranker å’Œ generator æ‰€æœ‰éšæ®µ

## åŸ·è¡Œç¯„ä¾‹

```bash
# åŸ·è¡ŒåŸºæœ¬ç¯„ä¾‹
python main.py

# åŸ·è¡Œè©³ç´°ä½¿ç”¨ç¯„ä¾‹
python example_usage.py

# æ¸¬è©¦ API é€£æ¥
python test_api.py

# æ¸¬è©¦é…ç½®ç³»çµ±
python test_config.py

# æ¸¬è©¦ä¸­æ–‡å›ç­”åŠŸèƒ½
python test_chinese_response.py

# æ¸¬è©¦è©•ä¼°åŠŸèƒ½
python test_evaluation.py

# æ¸¬è©¦æ–‡æœ¬åˆ†å¡ŠåŠŸèƒ½
python test_chunking.py

# ä½¿ç”¨è‡ªå®šç¾©åƒæ•¸åŸ·è¡Œ
python main.py --embedding-model "custom-model" --verbose

# å¿«é€Ÿæ¸¬è©¦è³‡æ–™é›†åŠŸèƒ½
python test_quick_dataset.py

# å¿«é€Ÿæ¸¬è©¦è³‡æ–™é›†ï¼ˆåªè™•ç†ç¬¬ä¸€è¡Œï¼‰
python main.py --dataset-name "your_dataset" --quick-test

# å®Œæ•´æ¸¬è©¦è³‡æ–™é›†
python main.py --dataset-name "your_dataset"
```

## é…ç½®é¸é …

### æ¨¡å‹é¸æ“‡
- **Embedding æ¨¡å‹**: `Qwen3-Embedding-4B`
- **Reranker æ¨¡å‹**: `bge-reranker-v2-m3`
- **Generator æ¨¡å‹**: `Qwen2.5-7B-Instruct`

### åƒæ•¸èª¿æ•´
- **æª¢ç´¢æ•¸é‡**: `top_k` åƒæ•¸æ§åˆ¶æª¢ç´¢å’Œé‡æ–°æ’åºçš„æ–‡ä»¶æ•¸é‡
- **ç”Ÿæˆåƒæ•¸**: `max_tokens` å’Œ `temperature` æ§åˆ¶ç”Ÿæˆå“è³ª

## éŒ¯èª¤è™•ç†

ç¨‹å¼åŒ…å«å®Œæ•´çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶ï¼š
- API é€£æ¥éŒ¯èª¤
- æ¨¡å‹è¼‰å…¥å¤±æ•—
- å‘é‡è¨ˆç®—éŒ¯èª¤
- æ–‡ä»¶è™•ç†ç•°å¸¸

## æ•ˆèƒ½å„ªåŒ–

- ä½¿ç”¨é¤˜å¼¦ç›¸ä¼¼åº¦é€²è¡Œå‘é‡æ¯”è¼ƒ
- æ”¯æ´æ‰¹é‡æ–‡ä»¶è™•ç†
- è¨˜æ†¶é«”ä¸­çš„å‘é‡å„²å­˜
- å¯é…ç½®çš„æª¢ç´¢åƒæ•¸

## æ“´å±•åŠŸèƒ½

å¯ä»¥è¼•é¬†æ“´å±•ä»¥ä¸‹åŠŸèƒ½ï¼š
- æŒä¹…åŒ–å‘é‡å„²å­˜ï¼ˆå¦‚ Chromaã€Pineconeï¼‰
- æ›´å¤šç›¸ä¼¼åº¦è¨ˆç®—æ–¹æ³•
- è‡ªå®šç¾© prompt æ¨¡æ¿
- æ‰¹æ¬¡è™•ç†æ”¯æ´
- å¿«å–æ©Ÿåˆ¶

## è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Request ä¾†æ”¹å–„é€™å€‹å°ˆæ¡ˆã€‚

## æˆæ¬Š

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ã€‚ 