import requests
import chromadb
from chromadb.config import Settings
from typing import List, Dict, Any
from dataclasses import dataclass
from config import get_config
from .text_chunker import DocumentChunker, TextChunker

@dataclass
class Document:
    """æ–‡ä»¶è³‡æ–™çµæ§‹"""
    content: str
    metadata: Dict[str, Any] = None
    score: float = 0.0

class EmbeddingAPI:
    """Embedding API å®¢æˆ¶ç«¯"""
    def __init__(self, api_key: str = None, base_url: str = None, model: str = None):
        config = get_config()
        self.api_key = config.retrieval_reranker_api_key
        self.base_url = base_url or config.retriever_base_url
        self.model = model or config.embedding_model
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
    
    def get_embedding(self, text: str, model: str = None) -> List[float]:
        """ç²å–æ–‡æœ¬çš„ embedding"""
        if not text or not text.strip():
            raise Exception("æ–‡æœ¬å…§å®¹ç‚ºç©º")
        
        data = {
            "input": text,
            "model": model or self.model
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/embeddings",
                headers=self.headers,
                json=data,
                timeout=30  # æ·»åŠ è¶…æ™‚
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    embedding = result["data"][0]["embedding"]
                    if embedding and len(embedding) > 0:
                        return embedding
                    else:
                        raise Exception("API è¿”å›çš„ embedding ç‚ºç©º")
                else:
                    raise Exception("API è¿”å›çš„æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º")
            else:
                raise Exception(f"API è«‹æ±‚å¤±æ•—: {response.status_code} - {response.text}")
                
        except requests.exceptions.RequestException as e:
            raise Exception(f"ç¶²çµ¡è«‹æ±‚éŒ¯èª¤: {e}")
        except Exception as e:
            raise Exception(f"ç²å– embedding æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

class ChromaVectorStore:
    """ä½¿ç”¨ Chroma çš„å‘é‡å„²å­˜"""
    def __init__(
        self, 
        collection_name: str = "rag_documents", 
        persist_directory: str = "./chroma_db",
        enable_chunking: bool = True,
        chunk_size: int = 512,
        chunk_overlap: int = 200
    ):
        self.collection_name = collection_name
        self.persist_directory = persist_directory
        self.enable_chunking = enable_chunking
        
        # åˆå§‹åŒ– Chroma å®¢æˆ¶ç«¯
        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # ç²å–æˆ–å‰µå»ºé›†åˆ
        try:
            self.collection = self.client.get_collection(name=collection_name)
            print(f"âœ… è¼‰å…¥ç¾æœ‰é›†åˆ: {collection_name}")
        except:
            self.collection = self.client.create_collection(
                name=collection_name,
                metadata={"description": "RAG Pipeline æ–‡ä»¶é›†åˆ"}
            )
            print(f"âœ… å‰µå»ºæ–°é›†åˆ: {collection_name}")
        
        # Embedding API å®¢æˆ¶ç«¯
        self.embedding_api = EmbeddingAPI()
        
        # æ–‡æœ¬åˆ†å¡Šå™¨
        if self.enable_chunking:
            self.chunker = DocumentChunker(
                TextChunker(
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap
                )
            )
            print(f"âœ… å•Ÿç”¨æ–‡æœ¬åˆ†å¡Š (chunk_size={chunk_size}, overlap={chunk_overlap})")
        else:
            self.chunker = None
            print("â­ï¸ ç¦ç”¨æ–‡æœ¬åˆ†å¡Š")
    
    def add_documents(self, documents: List[Document]):
        """æ·»åŠ æ–‡ä»¶åˆ° Chroma å‘é‡å„²å­˜"""
        print(f"ğŸ“š æ·»åŠ  {len(documents)} å€‹æ–‡ä»¶åˆ° Chroma...")
        
        # å¦‚æœå•Ÿç”¨åˆ†å¡Šï¼Œå…ˆé€²è¡Œæ–‡æœ¬åˆ†å¡Š
        if self.enable_chunking and self.chunker:
            print("ğŸ”„ é€²è¡Œæ–‡æœ¬åˆ†å¡Š...")
            chunked_documents = self.chunker.chunk_documents(documents)
            print(f"ğŸ“„ åˆ†å¡Šå¾Œå¾—åˆ° {len(chunked_documents)} å€‹æ–‡æœ¬å¡Š")
            # è‹¥åˆ†å¡Šçµæœç‚ºç©ºï¼Œå›é€€ç‚ºåŸå§‹æ–‡æª”
            documents_to_add = chunked_documents or documents
        else:
            documents_to_add = documents
        
        # æº–å‚™æ•¸æ“š
        ids = []
        texts = []
        metadatas = []
        embeddings = []
        
        # å…ˆå˜—è©¦ç²å–ä¸€å€‹ embedding ä¾†ç¢ºå®šç¶­åº¦
        embedding_dimension = None
        try:
            test_embedding = self.embedding_api.get_embedding("test")
            embedding_dimension = len(test_embedding)
            print(f"âœ… ç¢ºèª embedding ç¶­åº¦: {embedding_dimension}")
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•ç¢ºå®š embedding ç¶­åº¦: {e}")
            embedding_dimension = 1536  # é è¨­ç¶­åº¦
        
        for i, doc in enumerate(documents_to_add):
            # ç”Ÿæˆå”¯ä¸€ ID
            doc_id = f"doc_{i}_{hash(doc.content) % 10000}"
            ids.append(doc_id)
            
            # æ–‡æœ¬å…§å®¹
            texts.append(doc.content)
            
            # å…ƒæ•¸æ“š
            metadata = doc.metadata or {}
            metadata.update({
                "source": "rag_pipeline",
                "content_length": len(doc.content),
                "is_chunked": self.enable_chunking
            })
            metadatas.append(metadata)
            
            # ç²å– embedding
            try:
                embedding = self.embedding_api.get_embedding(doc.content)
                if embedding and len(embedding) > 0:
                    embeddings.append(embedding)
                else:
                    raise Exception("ç²å–åˆ°çš„ embedding ç‚ºç©º")
            except Exception as e:
                print(f"âš ï¸ ç²å– embedding å¤±æ•— (æ–‡æª” {i+1}): {e}")
                # å¦‚æœ API å¤±æ•—ï¼Œä½¿ç”¨é›¶å‘é‡ä½œç‚ºå‚™ç”¨
                zero_embedding = [0.0] * embedding_dimension
                embeddings.append(zero_embedding)
        
        # è‹¥æ²’æœ‰å¯æ·»åŠ çš„æ–‡æª”ï¼Œç›´æ¥è¿”å›
        if not ids and len(documents_to_add) == 0:
            print("âš ï¸ æ²’æœ‰å¯æ·»åŠ çš„æ–‡ä»¶ï¼Œè·³é")
            return

        # æ‰¹é‡æ·»åŠ åˆ° Chroma
        try:
            if not ids or not embeddings:
                print("âš ï¸ ç©ºçš„ ids æˆ– embeddingsï¼Œè·³éæ·»åŠ ")
                return
            self.collection.add(
                ids=ids,
                documents=texts,
                metadatas=metadatas,
                embeddings=embeddings
            )
            print(f"âœ… æˆåŠŸæ·»åŠ  {len(documents_to_add)} å€‹æ–‡ä»¶åˆ° Chroma")
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡ä»¶åˆ° Chroma å¤±æ•—: {e}")
            raise
    
    def search(self, query: str, top_k: int = 10) -> List[Document]:
        """æœå°‹ç›¸ä¼¼æ–‡ä»¶"""
        try:
            # ç²å–æŸ¥è©¢çš„ embedding
            query_embedding = self.embedding_api.get_embedding(query)
            
            # åœ¨ Chroma ä¸­æœå°‹
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=["documents", "metadatas", "distances"]
            )
            
            # è½‰æ›ç‚º Document ç‰©ä»¶
            documents = []
            if results["documents"] and results["documents"][0]:
                for i, (doc_text, metadata, distance) in enumerate(zip(
                    results["documents"][0],
                    results["metadatas"][0],
                    results["distances"][0]
                )):
                    # å°‡è·é›¢è½‰æ›ç‚ºç›¸ä¼¼åº¦åˆ†æ•¸ (Chroma ä½¿ç”¨æ­å¹¾é‡Œå¾—è·é›¢)
                    similarity_score = 1.0 / (1.0 + distance)
                    
                    doc = Document(
                        content=doc_text,
                        metadata=metadata,
                        score=similarity_score
                    )
                    documents.append(doc)
            
            return documents
            
        except Exception as e:
            print(f"âŒ Chroma æœå°‹å¤±æ•—: {e}")
            return []
    
    def get_collection_info(self) -> Dict[str, Any]:
        """ç²å–é›†åˆè³‡è¨Š"""
        try:
            count = self.collection.count()
            return {
                "collection_name": self.collection_name,
                "document_count": count,
                "persist_directory": self.persist_directory
            }
        except Exception as e:
            print(f"âŒ ç²å–é›†åˆè³‡è¨Šå¤±æ•—: {e}")
            return {}
    
    def delete_collection(self):
        """åˆªé™¤é›†åˆ"""
        try:
            self.client.delete_collection(name=self.collection_name)
            print(f"âœ… åˆªé™¤é›†åˆ: {self.collection_name}")
        except Exception as e:
            print(f"âŒ åˆªé™¤é›†åˆå¤±æ•—: {e}")

def retriever(query: str, vector_store: ChromaVectorStore, top_k: int = 20) -> List[Document]:
    """
    Retriever å‡½æ•¸ï¼šå¾å‘é‡å„²å­˜ä¸­æª¢ç´¢ç›¸é—œæ–‡ä»¶
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        vector_store: å‘é‡å„²å­˜å¯¦ä¾‹
        top_k: è¿”å›çš„æ–‡ä»¶æ•¸é‡
    
    Returns:
        ç›¸é—œæ–‡ä»¶åˆ—è¡¨
    """
    print(f"ğŸ” æª¢ç´¢æŸ¥è©¢: {query}")
    documents = vector_store.search(query, top_k=top_k)
    print(f"ğŸ“„ æª¢ç´¢åˆ° {len(documents)} å€‹æ–‡ä»¶")
    return documents

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œä¿ç•™ VectorStore åˆ¥å
VectorStore = ChromaVectorStore
