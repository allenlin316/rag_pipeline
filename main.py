import os
import json
from typing import List, Dict, Any, Optional, get_origin, get_args
import csv
from datetime import datetime, timezone, timedelta
import numpy as np
from dataclasses import dataclass
from config import get_config, init_config

# å°å…¥æ–°çš„æ¨¡çµ„
from src.retriever import Document, ChromaVectorStore, retriever
from src.reranker import reranker
from src.generator import generator
from src.rag_deepeval import (
    evaluate_rag_pipeline,
    CustomLLMJudge,
)
from datasets import load_dataset
from pydantic import BaseModel

def rag_pipeline(query: str, vector_store: ChromaVectorStore, expected_output_text: Optional[str] = None) -> str:
    """
    å®Œæ•´çš„ RAG Pipeline
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        vector_store: å‘é‡å„²å­˜å¯¦ä¾‹
        expected_output_text: ç•¶æœ‰è³‡æ–™é›†æ™‚ï¼Œç›´æ¥å‚³å…¥ answer ä½œç‚ºè©•ä¼°çš„ expected output
    """
    config = get_config()
    print("ğŸš€ é–‹å§‹ RAG Pipeline")
    print("=" * 50)
    
    # 1. Retriever éšæ®µ
    retrieved_docs = retriever(query, vector_store, top_k=config.retriever_top_k)
    
    # 2. Reranker éšæ®µ (å¯é¸)
    if config.enable_reranker:
        print(f"ğŸ”„ å•Ÿç”¨ {config.reranker_model} Reranker éšæ®µ")
        reranked_docs = reranker(query, retrieved_docs, top_k=config.reranker_top_k)
    else:
        print("â­ï¸  è·³é Reranker éšæ®µ")
        reranked_docs = retrieved_docs[:config.reranker_top_k]
    
    # 3. Generator éšæ®µ
    answer = generator(query, reranked_docs)

    # 3.5 å„²å­˜ inputã€æª¢ç´¢çµæœï¼ˆpre-rerank å…¨éƒ¨ï¼‰ã€å‰ top-k rerank æ–‡ä»¶ã€èˆ‡ generation çµæœï¼ˆJSONLï¼‰
    try:
        if getattr(config, "enable_results_logging", False):
            results_path = getattr(config, "results_jsonl_path", "results_logs.jsonl")
            top_k = getattr(config, "reranker_top_k", 3)
            top_docs = reranked_docs[:top_k]
            # åºåˆ—åŒ–ï¼šæª¢ç´¢çµæœï¼ˆpre-rerank å…¨éƒ¨ï¼‰
            retrieved_serialized_docs = []
            for idx, doc in enumerate(retrieved_docs, start=1):
                try:
                    retrieved_serialized_docs.append({
                        "retrieval_rank": idx,
                        "score": getattr(doc, "score", None),
                        "content": getattr(doc, "content", None),
                        "metadata": getattr(doc, "metadata", None),
                    })
                except Exception:
                    retrieved_serialized_docs.append({
                        "retrieval_rank": idx,
                        "score": None,
                        "content": None,
                        "metadata": None,
                    })
            # ç”¢ç”Ÿ UTC+8 æ™‚é–“å­—ä¸²
            tz_utc8 = timezone(timedelta(hours=8))
            timestamp_utc8 = datetime.now(tz_utc8).strftime("%Y-%m-%d %H:%M:%S %z")
            # åºåˆ—åŒ–æ–‡ä»¶
            serialized_docs = []
            for idx, doc in enumerate(top_docs, start=1):
                try:
                    serialized_docs.append({
                        "rank": idx,
                        "score": getattr(doc, "score", None),
                        "content": getattr(doc, "content", None),
                        "metadata": getattr(doc, "metadata", None),
                    })
                except Exception:
                    serialized_docs.append({
                        "rank": idx,
                        "score": None,
                        "content": None,
                        "metadata": None,
                    })
            record = {
                "timestamp_utc8": timestamp_utc8,
                "query": query,
                "retrieved_docs": retrieved_serialized_docs,
                "top5_reranked_docs": serialized_docs,
                "answer": answer,
            }
            with open(results_path, mode="a", encoding="utf-8") as f:
                f.write(json.dumps(record, ensure_ascii=False) + "\n")
            print(f"ğŸ’¾ å·²å„²å­˜æŸ¥è©¢èˆ‡ç”Ÿæˆçµæœåˆ° {results_path}")
    except Exception as e:
        print(f"âš ï¸ å„²å­˜çµæœåˆ° JSONL å¤±æ•—: {e}")

    # 4. è©•ä¼°ï¼ˆå¯é¸ï¼‰
    if getattr(config, "enable_eval", True):
        print("\nğŸ§ª åŸ·è¡Œè©•ä¼°...")
        # æº–å‚™ retrieval contextsï¼ˆå–å›å‚³æ–‡ä»¶çš„ content ä½œç‚ºä¸Šä¸‹æ–‡ï¼‰
        retrieval_context = [d.content for d in reranked_docs]
        # å„ªå…ˆä½¿ç”¨å‡½æ•¸åƒæ•¸ï¼Œå†å›é€€ configï¼Œæœ€å¾Œå›é€€ç©ºå­—ä¸²
        expected_output = str((expected_output_text if expected_output_text is not None else getattr(config, "expected_output_text", "")) or "")
        # æŒ‡æ¨™ï¼šretrieval evalï¼ˆprecisionã€recallã€relevancyï¼‰ï¼Œgenerator evalï¼ˆfaithfulnessã€answer relevancyï¼‰
        metrics = [
            "contextual_precision",
            "contextual_recall",
            "contextual_relevancy",
            "faithfulness",
            "answer_relevancy",
        ]
        try:
            results = evaluate_rag_pipeline(
                query=query,
                actual_output=answer,
                expected_output=expected_output,
                retrieval_context=retrieval_context,
                metrics=metrics,
                llm_judge_model=getattr(config, 'llm_judge_model', 'gpt-oss-120b')
            )
            print("\nğŸ“ˆ è©•ä¼°çµæœï¼š")
            for k, v in results.items():
                print(f"  {k}: {v.get('score')} | {v.get('reason')}")

            # å¯é¸ï¼šå„²å­˜åˆ° CSV
            if getattr(config, "enable_metrics_logging", False):
                try:
                    # è’é›†æ¨¡å‹è³‡è¨Š
                    embedding_model = getattr(config, "embedding_model", None)
                    reranker_model = getattr(config, "reranker_model", None)
                    generator_model = getattr(config, "generator_model", None)

                    # è’é›†æŒ‡æ¨™åˆ†æ•¸
                    faithfulness = (results.get("faithfulness") or {}).get("score")
                    answer_relevancy = (results.get("answer_relevancy") or {}).get("score")
                    contextual_precision = (results.get("contextual_precision") or {}).get("score")
                    contextual_recall = (results.get("contextual_recall") or {}).get("score")
                    contextual_relevancy = (results.get("contextual_relevancy") or {}).get("score")

                    # è’é›†æŒ‡æ¨™åŸå› 
                    faithfulness_reason = (results.get("faithfulness") or {}).get("reason")
                    answer_relevancy_reason = (results.get("answer_relevancy") or {}).get("reason")
                    contextual_precision_reason = (results.get("contextual_precision") or {}).get("reason")
                    contextual_recall_reason = (results.get("contextual_recall") or {}).get("reason")
                    contextual_relevancy_reason = (results.get("contextual_relevancy") or {}).get("reason")

                    csv_path = getattr(config, "metrics_csv_path", "metrics_logs.csv")
                    # é¦–æ¬¡å»ºç«‹æˆ–ç©ºæª”éƒ½å¯«å…¥è¡¨é ­
                    try:
                        file_empty = (not os.path.exists(csv_path)) or os.path.getsize(csv_path) == 0
                    except Exception:
                        file_empty = True

                    # å»ºç«‹/é™„åŠ  CSV
                    with open(csv_path, mode="a", encoding="utf-8", newline="") as f:
                        writer = csv.DictWriter(
                            f,
                            fieldnames=[
                                "timestamp_utc8",
                                "query",
                                "embedding_model",
                                "reranker_model",
                                "generator_model",
                                "faithfulness",
                                "faithfulness_reason",
                                "answer_relevancy",
                                "answer_relevancy_reason",
                                "contextual_precision",
                                "contextual_precision_reason",
                                "contextual_recall",
                                "contextual_recall_reason",
                                "contextual_relevancy",
                                "contextual_relevancy_reason",
                            ],
                        )
                        if file_empty:
                            writer.writeheader()
                        # ç”¢ç”Ÿ UTC+8 æ™‚é–“å­—ä¸²ï¼ˆä¾‹å¦‚ 2025-08-19 14:30:00 +0800ï¼‰
                        tz_utc8 = timezone(timedelta(hours=8))
                        timestamp_utc8 = datetime.now(tz_utc8).strftime("%Y-%m-%d %H:%M:%S %z")
                        writer.writerow({
                            "timestamp_utc8": timestamp_utc8,
                            "query": query,
                            "embedding_model": embedding_model,
                            "reranker_model": reranker_model,
                            "generator_model": generator_model,
                            "faithfulness": faithfulness,
                            "faithfulness_reason": faithfulness_reason,
                            "answer_relevancy": answer_relevancy,
                            "answer_relevancy_reason": answer_relevancy_reason,
                            "contextual_precision": contextual_precision,
                            "contextual_precision_reason": contextual_precision_reason,
                            "contextual_recall": contextual_recall,
                            "contextual_recall_reason": contextual_recall_reason,
                            "contextual_relevancy": contextual_relevancy,
                            "contextual_relevancy_reason": contextual_relevancy_reason,
                        })
                    print(f"ğŸ’¾ å·²å„²å­˜è©•ä¼°çµæœåˆ° {csv_path}")
                except Exception as e:
                    print(f"âš ï¸ å„²å­˜è©•ä¼°çµæœåˆ° CSV å¤±æ•—: {e}")
        except Exception as e:
            print(f"âš ï¸ è©•ä¼°å¤±æ•—: {e}")
    
    print("=" * 50)
    print("âœ… RAG Pipeline å®Œæˆ")
    
    return answer

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # åˆå§‹åŒ–é…ç½®
    config = init_config()
    
    # é¡¯ç¤º Reranker è¨­å®š
    print(f"ğŸ”„ Reranker è¨­å®š: {'å•Ÿç”¨' if config.enable_reranker else 'ç¦ç”¨'}")

    # è‹¥æä¾› datasetï¼Œæ”¹ç‚ºæ‰¹æ¬¡æµç¨‹
    if getattr(config, "dataset_name", None):
        chosen_split = getattr(config, "dataset_split", None)
        if chosen_split:
            ds = load_dataset(config.dataset_name, split=chosen_split, token=getattr(config, "hf_token", None))
            datasets_to_run = [(chosen_split, ds)]
        else:
            ds_all = load_dataset(config.dataset_name, token=getattr(config, "hf_token", None))
            # æ”¶é›†æ‰€æœ‰å¯ç”¨ splits
            if hasattr(ds_all, "keys"):
                datasets_to_run = [(name, ds_all[name]) for name in ds_all.keys()]
            else:
                datasets_to_run = [("unspecified", ds_all)]
        print("ğŸ“¦ ä½¿ç”¨ä»¥ä¸‹ splits é€²è¡Œæ¸¬è©¦: " + ", ".join([name for name, _ in datasets_to_run]))
        ctx_field = getattr(config, "context_field", "context")
        q_field = getattr(config, "question_field", "question")
        a_field = getattr(config, "answer_field", "answer")

        for split_name, split_ds in datasets_to_run:
            print(f"\n===== Split: {split_name} =====")
            
            # ç‚ºæ¯å€‹ split å‰µå»ºæ–°çš„å‘é‡å„²å­˜å¯¦ä¾‹
            vector_store = ChromaVectorStore(
                collection_name=f"{config.collection_name}_{split_name}",
                persist_directory=config.persist_directory,
                enable_chunking=config.enable_chunking,
                chunk_size=getattr(config, 'chunk_size', 512),
                chunk_overlap=getattr(config, 'chunk_overlap', 200),
                reset=getattr(config, 'reset_collection', False)
            )

            # æª¢æŸ¥æ˜¯å¦ç‚ºå¿«é€Ÿæ¸¬è©¦æ¨¡å¼
            if getattr(config, "quick_test", False):
                print("âš¡ å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼šåªè™•ç†ç¬¬ä¸€è¡Œè³‡æ–™")
                split_ds = split_ds.select(range(15))  # åªå–å‰ 15 è¡Œ
            
            # å°‡è©² split çš„æ‰€æœ‰ context åŠ å…¥çŸ¥è­˜åº«
            print("ğŸ“š å°‡ contexts åŠ å…¥ Chroma...")
            docs = []
            for i, row in enumerate(split_ds):
                context_text = row.get(ctx_field)
                if not context_text:
                    continue
                docs.append(Document(str(context_text)))
            if docs:
                vector_store.add_documents(docs)

            # é€ç­†åŸ·è¡Œ
            print("ğŸš€ é€ç­†åŸ·è¡Œ RAG èˆ‡è©•ä¼°ï¼ˆappend CSVï¼‰...")
            for idx, row in enumerate(split_ds):
                query = str(row.get(q_field, "")).strip()
                gt_answer = str(row.get(a_field, "")).strip()
                if not query:
                    continue
                print(f"\n----- Case {idx+1} -----")
                print(f"Q: {query}")
                print(f"Context: {row.get(ctx_field, '')[:100]}...")  # é¡¯ç¤ºå‰100å€‹å­—ç¬¦çš„context
                ans = rag_pipeline(query, vector_store, expected_output_text=gt_answer)
                print(f"A: {ans}")
                print(f"Expected: {gt_answer}")
                
                # å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ä¸‹åªè™•ç†ç¬¬ä¸€è¡Œå°±çµæŸ
                if getattr(config, "quick_test", False):
                    print("âš¡ å¿«é€Ÿæ¸¬è©¦å®Œæˆï¼Œåªè™•ç†äº†ç¬¬ä¸€è¡Œè³‡æ–™")
                    break

        print("\nâœ… Dataset æ‰¹æ¬¡æµç¨‹å®Œæˆ")
    else:
        # å–®ä¾‹ç¤ºç¯„æ¨¡å¼ - å‰µå»º Chroma å‘é‡å„²å­˜
        vector_store = ChromaVectorStore(
            collection_name=config.collection_name,
            persist_directory=config.persist_directory,
            enable_chunking=config.enable_chunking,
            chunk_size=getattr(config, 'chunk_size', 512),
            chunk_overlap=getattr(config, 'chunk_overlap', 200),
            reset=getattr(config, 'reset_collection', False)
        )
        
        # é¡¯ç¤ºé›†åˆè³‡è¨Š
        info = vector_store.get_collection_info()
        print(f"ğŸ“Š é›†åˆè³‡è¨Š: {info}")
        
        # ç¤ºä¾‹æ–‡ä»¶
        sample_documents = [
            Document("äººå·¥æ™ºæ…§ï¼ˆAIï¼‰æ˜¯è¨ˆç®—æ©Ÿç§‘å­¸çš„ä¸€å€‹åˆ†æ”¯ï¼Œè‡´åŠ›æ–¼å‰µå»ºèƒ½å¤ åŸ·è¡Œé€šå¸¸éœ€è¦äººé¡æ™ºèƒ½çš„ä»»å‹™çš„ç³»çµ±ã€‚"),
            Document("æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹å­é›†ï¼Œå®ƒä½¿è¨ˆç®—æ©Ÿèƒ½å¤ å¾æ•¸æ“šä¸­å­¸ç¿’è€Œç„¡éœ€æ˜ç¢ºç·¨ç¨‹ã€‚"),
            Document("æ·±åº¦å­¸ç¿’æ˜¯æ©Ÿå™¨å­¸ç¿’çš„ä¸€å€‹åˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±¤ç¥ç¶“ç¶²çµ¡ä¾†è™•ç†è¤‡é›œçš„æ¨¡å¼è­˜åˆ¥ä»»å‹™ã€‚"),
            Document("è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹é ˜åŸŸï¼Œå°ˆæ³¨æ–¼è¨ˆç®—æ©Ÿç†è§£å’Œç”Ÿæˆäººé¡èªè¨€ã€‚"),
            Document("è¨ˆç®—æ©Ÿè¦–è¦ºæ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹åˆ†æ”¯ï¼Œä½¿è¨ˆç®—æ©Ÿèƒ½å¤ ç†è§£å’Œè§£é‡‹è¦–è¦ºä¿¡æ¯ã€‚")
        ]
        
        print("ğŸ“š æ·»åŠ ç¤ºä¾‹æ–‡ä»¶åˆ° Chroma...")
        vector_store.add_documents(sample_documents)
        
        # é¡¯ç¤ºæ›´æ–°å¾Œçš„é›†åˆè³‡è¨Š
        info = vector_store.get_collection_info()
        print(f"ğŸ“Š æ›´æ–°å¾Œé›†åˆè³‡è¨Š: {info}")
        
        # æ¸¬è©¦æŸ¥è©¢
        test_query = "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ"
        print(f"\nâ“ æ¸¬è©¦æŸ¥è©¢: {test_query}")
        
        # åŸ·è¡Œ RAG pipeline
        answer = rag_pipeline(test_query, vector_store)
        print(f"\nğŸ’¬ å›ç­”: {answer}")
        
        # é¡¯ç¤ºä½¿ç”¨æç¤º
        print(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print(f"   - å•Ÿç”¨ Reranker: python main.py --enable-reranker")
        print(f"   - ç¦ç”¨ Reranker: python main.py --disable-reranker")
        print(f"   - æ¸¬è©¦ä¸­æ–‡å›ç­”: python test_chinese_response.py")
